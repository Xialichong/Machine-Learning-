rm(list=ls())
setwd()
credit.df<- read.csv("D:/Machine Learning/Data/credit_dataset_final.csv", header = T,sep = ",")
attach(credit.df)
#????????????: 1.???????????????????????????????????????
#1.?????????
to.factors<- function(df, variables){
  for(variable in variables){
    df[[variable]]<- as.factor(df[[variable]])
  }
  return(df)
}

#2.?????????scale=T,????????? center=T#3.z-score normalizing
scale.features<- function(df, variables){
  for (variable in variables){
    df[variable]<- scale(df[variable],center = T, scale = T)
  }
  return(df)
}


numeric.vars<- c("Duration.of.Credit..month.","Age..years.","Credit.Amount")
credit.df<- scale.features(credit.df,numeric.vars)

categorial.vars<- c('Creditability','Account.Balance','Payment.Status.of.Previous.Credit','Purpose','Value.Savings.Stocks','Length.of.current.employment','Instalment.per.cent',
                    'Sex...Marital.Status', 'Guarantors','Duration.in.Current.address','Most.valuable.available.asset', 'Concurrent.Credits', 'Type.of.apartment','No.of.Credits.at.this.Bank',
                    'Occupation', 'No.of.dependents','Telephone', 'Foreign.Worker')
credit.df<- to.factors(df= credit.df, variables = categorial.vars)

#split data into training and test in 60:40
indexes<- sample(1:nrow(credit.df), size = 0.6*nrow(credit.df))
train.data<- credit.df[indexes,]
test.data<-credit.df[-indexes,]

#??????????????????
library(caret) #feature selection algorithm
library(randomForest) 

run.feature.selection<- function(num.iters=20, feature.vars, class.var){
  set.seed(10)
  variable.sizes<- 1:10
  control<- rfeControl(functions = rfFuncs, method = "cv",
                       verbose = FALSE, returnResamp = "all",
                       number = num.iters)
  results.rfe<- rfe(x=feature.vars,y=class.var,sizes = variable.sizes,
                    rfeControl = control)
  return(results.rfe)
}

#??????
rfe.results<- run.feature.selection(feature.vars = train.data[,-1],class.var = train.data[,1])
rfe.results


#??????????????????????????????,????????????????????????,???????????????????????????????????????????????????????????????,????????????????????????????????????????????????????????????????????????,??????????????????????????????
#???????????????,????????????????????????????????????
library(caret)
library(ROCR)
library(ggplot2)
test.feature.vars<-test.data[,-1]
test.class.var<- test.data[,1]
formula.init<-"Creditability ~ ."
formula.init<-as.formula(formula.init)
lr.model<-glm(formula = formula.init,data = train.data,family = "binomial")
summary(lr.model)

lr.predictions <- predict(lr.model, test.data,type="response") 
lr.predictions<-round(lr.predictions)
confusionMatrix(data = lr.predictions,reference = test.class.var,positive = '1')

#?????????,???????????????????????????????????????????????????????????????,???????????????????????????
formula<-"Creditability ~ ."
formula<-as.formula(formula)
control<- trainControl(method = "repeatedcv",number = 10, repeats = 2)
model<- train(formula, data = train.data, method="glm",trControl=control)
importance<- varImp(model,scale = FALSE)
plot(importance)
#?????????????????????,????????????
formula.new<-"Creditability~Account.Balance+Purpose+Payment.Status.of.Previous.Credit+Value.Savings.Stocks+Duration.in.Current.address"
formula.new<- as.formula(formula.new)
lr.model.new<- glm(formula = formula.new,data = train.data,family = "binomial")
lr.predictions.new<-predict(lr.model.new,test.data, type = "response")
lr.predictions.new<-round(lr.predictions.new)
confusionMatrix(data = lr.predictions.new,reference = test.class.var, positive = '1')

#????????????????????????????????????????????????,??????????????????????????????,????????????????????????,?????????????????????????????????????????????
lr.model.best<- lr.model
lr.predictions.values<- predict(lr.model.best,test.feature.vars,type = "response")
predictions<-prediction(lr.predictions.values,test.class.var)
par(mfrow=c(1,2))
plot.roc.curve(predictions,title.text="LR ROC Curve")    
plot.pr.curve(predictions,title.text="LR Prediction/Recall Curve")
